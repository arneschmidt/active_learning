# This is the main config. Parameters are updated and possibly overwritten by dataset dependent configs.
random_seed: 0
model:
  test_on_the_fly: True
  batch_size: 8
  epochs: 200
  learning_rate: 0.0001
  lr_decrease_epochs: 100 # lr will be multiplied by 0.1 after this epoch; -1 for disabling
  optimizer: adam # adam, sgd
  class_weighted_loss: True
  loss_function: categorical_crossentropy # "categorical_crossentropy", "focal_loss"
  metrics_patch_level: True
  metrics_wsi_level: True
  metrics_for_monitoring: val_cohens_quadratic_kappa
  load_model: None # 'None' or path to experiment folder which containes 'models' directory with .h5 files
  save_model: False # True or False
  feature_extractor:
    type: efficientnetb3 # "fsconv", "simple_cnn", "mobilenetv2", "resnet50", "efficientnetb0", "efficientnetb1", "eff.."
    global_max_pooling: False
    num_output_features: 128 # feature dimension of feature extractor output, set to 0 to skip this layer
    output_activation: relu # sigmoid, relu
    dropout: 0.5
    multiscale: True
  head:
    type: bnn # deterministic, bnn
    deterministic:
      dropout: 0.0
      number_hidden_units: 128 # feature dimension of hidden layer, set to 0 to skip this layer
      extra_layer: True
    bnn:
      number_hidden_units: 128
      kl_loss_factor: 1
      extra_layer: True
      weight_std: 0.1
  wsi_level_model:
    use: True # if False, the wsi metrics will be calculated based on the patch classiciation
    access_to_all_wsis: True # if False, only the acquired WSIs (with patch labels) are used for training
    learning_rate: 0.01
  acquisition:
    random: False # if True, all other acquisition parameters are ignored
    keep_trained_weights: False
    uncertainty_calculation: variance_based # variance_based, entropy_based
    focussed_epistemic: True
    aleatoric_factor: 0.5
    ood_factor: 2.0
    ood_k_neighbors: 50
    wsi_selection: uncertainty_mean # 'random', 'uncertainty_max', 'uncertainty_mean', 'gradual_learning'

data:
  dataset_config: ./dataset_dependent/panda/config.yaml
  supervision: active_learning # 'supervised', 'active_learning'
  augmentation:
    channel_shift_range: 0.2
    width_shift_range: 0.0 # fraction of total width <1
    height_shift_range: 0.0 # fraction of total height <1
    zoom_range: 0.0 # [1-zoom_range, 1+zoom_range]
    hue: 0.2 # between 0 and 1
    saturation: 0.2 # between 0 and 1
    contrast: 0.2 # between 0 and 1
    blur: 2 # sigma range for gaussian blur
    brightness: 0.2 # between 0 and 1
  active_learning:
    start:
      wsis_per_class: 5
      labels_per_class_and_wsi: 5 # -1 (all) or number of labels per wsi
    step:
      wsis: 10
      labels_per_wsi: 5
      flexible_labeling: True # if True, the labels of one step can be distributed freely within the selected WSIs
      total_steps: 18
      acceleration:
        use: False
        wsis: 100
        after_step: 5

logging:
  log_artifacts: True
  save_images: True
  interval: 5
  test_on_the_fly: True
  run_name: efficientnetb1
  tracking_url: /work/work_arne/mlflow_server