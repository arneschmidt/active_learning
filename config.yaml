# This is the main config. Parameters are updated and possibly overwritten by dataset dependent configs.
random_seed: 0
model:
  test_on_the_fly: True
  batch_size: 8
  epochs: 200
  learning_rate: 0.0001
  lr_decrease_epochs: 100 # lr will be multiplied by 0.1 after this epoch; -1 for disabling
  optimizer: adam # adam, sgd
  class_weighted_loss: True
  loss_function: categorical_crossentropy # "categorical_crossentropy", "focal_loss"
  metrics_patch_level: True
  metrics_wsi_level: True
  metrics_for_monitoring: val_cohens_quadratic_kappa # 'val_cohens_quadratic_kappa', 'val_f1_mean', 'None'
  load_model: None # 'None' or path to experiment folder which containes 'models' directory with .h5 files
  save_model: False # True or False
  feature_extractor:
    type: efficientnetb3 # "fsconv", "simple_cnn", "mobilenetv2", "resnet50", "efficientnetb0", "efficientnetb1", "eff.."
    global_max_pooling: False
    num_output_features: 128 # feature dimension of feature extractor output, set to 0 to skip this layer
    output_activation: relu # sigmoid, relu
    dropout: 0.5
    multiscale: True
  head:
    type: bnn # deterministic, bnn
    deterministic:
      dropout: 0.0
      number_hidden_units: 128 # feature dimension of hidden layer, set to 0 to skip this layer
      extra_layer: True
    bnn:
      number_hidden_units: 128
      kl_loss_factor: 1
      extra_layer: True
      weight_std: 0.05
  wsi_level_model:
    use: True # if False, the wsi metrics will be calculated based on the patch classiciation
    access_to_all_wsis: True # if False, only the acquired WSIs (with patch labels) are used for training
    learning_rate: 0.01
  acquisition:
    strategy: focal # focal, bald, epistemic, max_std, entropy,  det_entropy, random
    wsi_selection: uncertainty_max # 'random', 'uncertainty_max', 'uncertainty_mean', 'gradual_learning'
    keep_trained_weights: False
    focal:
      uncertainty_calculation: variance_based # variance_based, entropy_based
      focussed_epistemic: True
      ood_k_neighbors: 10
      aleatoric_factor: 0.5
      ood_factor: 1.0

data:
  dataset_config: ./dataset_dependent/panda/config.yaml
  supervision: active_learning # 'supervised', 'active_learning'
  augmentation:
    channel_shift_range: 0.2
    width_shift_range: 0.0 # fraction of total width <1
    height_shift_range: 0.0 # fraction of total height <1
    zoom_range: 0.0 # [1-zoom_range, 1+zoom_range]
    hue: 0.2 # between 0 and 1
    saturation: 0.2 # between 0 and 1
    contrast: 0.2 # between 0 and 1
    blur: 2 # sigma range for gaussian blur
    brightness: 0.2 # between 0 and 1
  active_learning:
    start:
      wsis_per_class: 25
      labels_per_class_and_wsi: 5 # -1 (all) or number of labels per wsi
    step:
      wsis: 100
      labels_per_wsi: 5
      flexible_labeling: True # if True, the labels of one step can be distributed freely within the selected WSIs
      wsi_independent_labeling: True
      total_steps: 20
      acceleration:
        use: False
        wsis: 100
        after_step: 4

logging:
  log_artifacts: True
  save_images: True
  interval: 5
  test_on_the_fly: True
  run_name: efficientnetb1
  tracking_url: /work/work_arne/mlflow_server
  test_pred_wsis:
    - '880a1fc64038757f0a332bdf8b81ef05'
    - '9f887e6311f6062c5741bfae853edb80'
    - 'd1766314b6c9a6f528f4cb6643798d41'
    - '8b1293493098a9bd999ef0c0dfdee134'
    - '4f066c3230d1e0d5f38a1837ea1a86e6'
    - 'b70651a991d293e0fa741ebb1754e15e'
    - '085d3e58058fa98dcbbdf64dacfe51be'
    - '3d0fd9f2d0044ce12d01fd6eeeb32161'
    - '1bf0cb1e3f0b2ce35b9b0a406cd225c5'
    - '136cae2844e9f6fd15f09ccc9453e0b6'
    - '267f0ec89d4c07f0a113e4ebceca7d54'
    - 'e610af2c9bdb892102c1c239c836121f'
    - '3ffc717414973b70eeebb9fb3d273c5d'
    - '24ecf26ce811ea7f0116d7ea5388bc4a'
    - '8fc10ce3188de7e919b9f08fe5e6993c'
    - '847c0798ac88eb76035bab0da44cb71c'
    - '5c6a9d25b7c602062f4095c2518aa46a'
    - '0b373388b189bee3ef6e320b841264dd'
    - '6210281e975f738e94a5643d366e3b09'
    - '2e24b2e477e5650b425ae9d58eff5654'
    - 'dd025ef522443f0f1e0f2282d7145dde'