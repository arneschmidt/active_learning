# This is the main config. Parameters are updated and possibly overwritten by dataset dependent configs.
model:
  mode: train # "train", "test", "predict", "predict_features"
  batch_size: 8
  epochs: 400
  learning_rate: 0.1
  optimizer: sgd
  class_weighted_loss: False
  loss_function: categorical_crossentropy # "categorical_crossentropy", "focal_loss"
  metrics_patch_level: True
  metrics_wsi_level: True
  metrics_for_monitoring: val_f1_mean
  load_model: None # 'None' or path to experiment folder which containes 'models' directory with .h5 files
  save_model: False # True or False
  feature_extractor:
    type: efficientnetb1 # "fsconv", "simple_cnn", "mobilenetv2", "resnet50", "efficientnetb0", "efficientnetb1", "eff.."
    global_max_pooling: False
    num_output_features: 8 # feature dimension of feature extractor output, set to 0 to skip this layer
    output_activation: sigmoid # sigmoid, relu
    dropout: 0.5
  head:
    type: deterministic # deterministic, gp, bnn
    deterministic:
      dropout: 0.2
      number_hidden_units: 0 # feature dimension of hidden layer, set to 0 to skip this layer
    gp:
      inducing_points: 200
      kl_weights: [1.0]
      kl_decrease: True
      kernel_trainable: False
      kernel_amplitude: 0.9
      kernel_length_scale: 0.1
    bnn:
      number_hidden_units: 100
      kl_loss_factor: 1

data:
  dataset_config: ./dataset_dependent/panda/config.yaml
  supervision: active_learning # 'supervised', 'active_learning'
  random_seed: 1
  augmentation:
    channel_shift_range: 0.2
    width_shift_range: 0.2 # fraction of total width <1
    height_shift_range: 0.2 # fraction of total height <1
    zoom_range: 0.2 # [1-zoom_range, 1+zoom_range]
    hue: 0.2 # between 0 and 1
    saturation: 0.2 # between 0 and 1
    contrast: 0.2 # between 0 and 1
    blur: 2 # sigma range for gaussian blur
    brightness: 0.2 # between 0 and 1
  active_learning:
    start:
      wsis_per_class: 1
      labels_per_class_and_wsi: -1 # -1 (all) or number of labels per wsi
    acquisition:
      strategy: max_class_var # 'max_var', 'bald', 'entropy', 'random', 'var_ratio', 'max_class_var'
      wsis: 5
      wsi_selection: gradual_learning # 'random', 'uncertainty_max', 'uncertainty_mean', 'gradual_learning'
      labels_per_wsi: 5
      after_epochs_of_no_improvement: 1
      after_acc_above: 0.8
      total_steps: 30

logging:
  log_artifacts: False
  interval: 5
  test_on_the_fly: True
  run_name: efficientnetb1
  tracking_url: /home/arne/projects/mlruns