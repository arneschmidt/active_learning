# This is the main config. Parameters are updated and possibly overwritten by dataset dependent configs.
random_seed: 0
model:
  test_on_the_fly: True
  batch_size: 16
  epochs: 2
  learning_rate: 0.0001
  lr_decrease_epochs: 1 # lr will be multiplied by 0.1 after this epoch; -1 for disabling
  optimizer: adam # adam, sgd
  class_weighted_loss: True
  loss_function: categorical_crossentropy # "categorical_crossentropy", "focal_loss"
  metrics_patch_level: True
  metrics_wsi_level: True
  metrics_for_monitoring: val_f1_mean
  load_model: None # 'None' or path to experiment folder which containes 'models' directory with .h5 files
  save_model: False # True or False
  feature_extractor:
    type: efficientnetb0 # "fsconv", "simple_cnn", "mobilenetv2", "resnet50", "efficientnetb0", "efficientnetb1", "eff.."
    global_max_pooling: False
    num_output_features: 128 # feature dimension of feature extractor output, set to 0 to skip this layer
    output_activation: relu # sigmoid, relu
    dropout: 0.5
    multiscale: False
  head:
    type: bnn # deterministic, bnn
    deterministic:
      dropout: 0.0
      number_hidden_units: 128 # feature dimension of hidden layer, set to 0 to skip this layer
      extra_layer: True
    bnn:
      number_hidden_units: 128
      kl_loss_factor: 1
      extra_layer: True
      weight_std: 0.1
  wsi_level_model:
    use: False # if false, the wsi metrics will be calculated based on the patch classiciation
    access_to_all_wsis: True # if False, only the acquired WSIs (with patch labels) are used for training
    learning_rate: 0.001
  acquisition:
    strategy: focal # focal, bald, epistemic, max_std, entropy,  det_entropy, random
    wsi_selection: uncertainty_mean # 'random', 'uncertainty_max', 'uncertainty_mean', 'gradual_learning'
    keep_trained_weights: False
    focal:
      uncertainty_calculation: variance_based # variance_based, entropy_based
      focussed_epistemic: True
      ood_k_neighbors: 10
      aleatoric_factor: 0.5
      ood_factor: 1.0
data:
#  dataset_config: ./dataset_dependent/panda/dummy_config.yaml
  dataset_config: ./dataset_dependent/panda/dummy_config.yaml
  supervision: active_learning # 'supervised', 'active_learning'
  augmentation:
    channel_shift_range: 0.2
    width_shift_range: 0.0 # fraction of total width <1
    height_shift_range: 0.0 # fraction of total height <1
    zoom_range: 0.0 # [1-zoom_range, 1+zoom_range]
    hue: 0.2 # between 0 and 1
    saturation: 0.2 # between 0 and 1
    contrast: 0.2 # between 0 and 1
    blur: 2 # sigma range for gaussian blur
    brightness: 0.2 # between 0 and 1
  active_learning:
    start:
      wsis_per_class: 2
      labels_per_class_and_wsi: 5 # -1 (all) or number of labels per wsi
    step:
      wsis: 1
      labels_per_wsi: 5
      flexible_labeling: False # if True, the labels of one step can be distributed freely within the selected WSIs
      wsi_independent_labeling: False
      total_steps: 18
      acceleration:
        use: True
        wsis: 2
        after_step: 2

logging:
  log_artifacts: True
  save_images: True
  interval: 1
  test_on_the_fly: True
  run_name: efficientnetb1
  tracking_url: /work/work_arne/mlflow_server
  test_pred_wsis:
    - '00c46b336b5b06423fcdec1b4d5bee06'
